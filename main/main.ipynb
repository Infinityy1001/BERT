{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify text with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial contains complete code to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews. In addition to training a model, you will learn how to preprocess text into an appropriate format.\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Load the IMDB dataset\n",
    "- Load a BERT model from TensorFlow Hub\n",
    "- Build your own model by combining BERT with a classifier\n",
    "- Train your own model, fine-tuning BERT as part of that\n",
    "- Save your model and use it to classify sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4167883098125458,\n",
       "  'token': 3000,\n",
       "  'token_str': 'paris',\n",
       "  'sequence': 'the capital of france is paris.'},\n",
       " {'score': 0.07141677290201187,\n",
       "  'token': 22479,\n",
       "  'token_str': 'lille',\n",
       "  'sequence': 'the capital of france is lille.'},\n",
       " {'score': 0.06339266896247864,\n",
       "  'token': 10241,\n",
       "  'token_str': 'lyon',\n",
       "  'sequence': 'the capital of france is lyon.'},\n",
       " {'score': 0.04444762319326401,\n",
       "  'token': 16766,\n",
       "  'token_str': 'marseille',\n",
       "  'sequence': 'the capital of france is marseille.'},\n",
       " {'score': 0.03029726631939411,\n",
       "  'token': 7562,\n",
       "  'token_str': 'tours',\n",
       "  'sequence': 'the capital of france is tours.'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"The capital of France is [MASK].\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633d7c9c6a4747b18d6e1b5e982a9859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743ffbb99f324b9c8eb1d4537d7262a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5258e768ddab4aacbc92f9b972858974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3acb1d66fd4de1ada5f596b4838ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465a19587b584e21b6d6c3f0dd24c4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46501a28e4a463f93992ac65fe0ad99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e321a4326c476cb4a64a39e3a49595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n",
      "\n",
      "The capital of France is Paris. This is the largest part of France; it's also the busiest in Europe. By the way, the capital was originally named after France's founder, Napoleon Bonaparte\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Charger un pipeline de génération de texte avec GPT-2\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Demander une question\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Générer une réponse\n",
    "response = generator(question, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Afficher la réponse générée\n",
    "print(response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of Egypt?\n",
      "\n",
      "This is where we will use the value of all those years for building our cities. In Egypt we've never used capital when we didn't have money. And this gives us the resources we need to get\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of Egypt?\"\n",
    "\n",
    "# Générer une réponse\n",
    "response = generator(question, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Afficher la réponse générée\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Victor Hugo?\n",
      "\n",
      "(From: The Amazing World of Harry Potter Fan Fic Archive)\n",
      "\n",
      "Virgil: The Man Who Dived Down [The Man Who Saved the World]\n",
      "\n",
      "(From: Harry Potter Book\n"
     ]
    }
   ],
   "source": [
    "question1= 'Who is Victor Hugo'\n",
    "\n",
    "reponse1 = generator(question1, max_length = 50, num_return_sequences = 1)\n",
    "\n",
    "print(reponse1[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
